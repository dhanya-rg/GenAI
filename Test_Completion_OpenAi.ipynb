{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "openai.api_key=os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "\n",
    "pd.DataFrame(openai.Model.list()['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7gNKYqUBOkjEk35n8Deb9ATo7dhew at 0x152cfef8680> JSON: {\n",
       "  \"id\": \"cmpl-7gNKYqUBOkjEk35n8Deb9ATo7dhew\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1690333814,\n",
       "  \"model\": \"text-curie-001\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"\\n\\n\\u00bfC\\u00f3mo est\\u00e1s?\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 15,\n",
       "    \"completion_tokens\": 10,\n",
       "    \"total_tokens\": 25\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Completion API\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    model='text-curie-001',\n",
    "    prompt=\"Act as an AI assistant and translate text to Spanish: How are you?\",\n",
    "    max_tokens=25,\n",
    "    temperature=0.6,\n",
    "    n=1\n",
    "\n",
    "    \n",
    ")\n",
    "response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7c2uOvpQddk78OrEVWe4wyaVoyqjg at 0x1f9ba3011d0> JSON: {\n",
       "  \"id\": \"cmpl-7c2uOvpQddk78OrEVWe4wyaVoyqjg\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1689302000,\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"\\n\\nNegative\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 16,\n",
       "    \"completion_tokens\": 4,\n",
       "    \"total_tokens\": 20\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "    model='text-davinci-003',\n",
    "    prompt=\"Act as an AI model to detect positive or negative tweets: You are an asshole\",\n",
    "    max_tokens=25,\n",
    "    temperature=0.6,\n",
    "    n=1\n",
    "\n",
    "    \n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "    model='text-davinci-003',\n",
    "    prompt=\"Act as an AI model to detect positive or negative tweets: You are an asshole\",\n",
    "    max_tokens=25,\n",
    "    temperature=0.6,\n",
    "    n=1\n",
    "\n",
    "    \n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7dqheoiRyQ9c5Wz07AQzjiOM1qnLX at 0x1bd18e7d450> JSON: {\n",
       "  \"id\": \"cmpl-7dqheoiRyQ9c5Wz07AQzjiOM1qnLX\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1689731738,\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"\\n\\nWie geht es dir?\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 16,\n",
       "    \"completion_tokens\": 9,\n",
       "    \"total_tokens\": 25\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "    model='text-davinci-003',\n",
    "    prompt=\"Act as an AI model to translate english text to German: How are you?\",\n",
    "    max_tokens=25,\n",
    "    temperature=0.6,\n",
    "    n=1\n",
    "\n",
    "    \n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Once there was a girl,\n",
      "Who loved to read,\n",
      "And she would often find,\n",
      "Sitting in\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time if I was Barbie, I would have looked at this clothing and picked out one outfit that worked and a shoe set that worked\n",
      "Once upon a time if I was Barbie, I would go to Paris to be discovered I would have I new fashion sense, 15,000 hairs\n",
      "Once upon a time if I was Barbie, being anatomically correct, then I would look at my children and ask, “Am I\n",
      "Once upon a time if I was Barbie, I would’ve gotten you a Ferrari. If I was Fisher-Price, I’\n",
      "Once upon a time if I was Barbie, my dress would automatically support my body’s contours. But now designers change the line often\n",
      "Once upon a time if I was Barbie, I would have bought this Swimsuit\n",
      "\n",
      "I would have been smart enough to rent this Best Convert\n",
      "Once upon a time if I was Barbie, I wouldn't consider dating David Hasselhoff\n",
      "\n",
      "When David Says I Love You (Barbie\n",
      "Once upon a time if I was Barbie, I would start each day\n",
      "\n",
      "with a rich cappuccino with a tall espresso and a\n",
      "Once upon a time if I was Barbie, I would have hanged from a hanger above my fireplace, my red undies flapping merrily\n",
      "Once upon a time if I was Barbie, I would've been delighted at my new White Mustang.\"\n",
      "\n",
      "That was my sign. I felt\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    " \n",
    "num_stories = 10\n",
    "prompt = \"Once upon a time if I was Barbie,\"\n",
    " \n",
    "# serial example, with one story completion per request\n",
    "for _ in range(num_stories):\n",
    "    response = openai.Completion.create(\n",
    "        model=\"curie\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=20,\n",
    "    )\n",
    "    # print story\n",
    "    print(prompt + response.choices[0].text)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
